{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "\n",
    "## SVM & Regularization\n",
    "\n",
    "\n",
    "For this homework we consider a set of observations on a number of red and white wine varieties involving their chemical properties and ranking by tasters. Wine industry shows a recent growth spurt as social drinking is on the rise. The price of wine depends on a rather abstract concept of wine appreciation by wine tasters, opinion among whom may have a high degree of variability. Pricing of wine depends on such a volatile factor to some extent. Another key factor in wine certification and quality assessment is physicochemical tests which are laboratory-based and takes into account factors like acidity, pH level, presence of sugar and other chemical properties. For the wine market, it would be of interest if human quality of tasting can be related to the chemical properties of wine so that certification and quality assessment and assurance process is more controlled.\n",
    "\n",
    "Two datasets are available of which one dataset is on red wine and have 1599 different varieties and the other is on white wine and have 4898 varieties. All wines are produced in a particular area of Portugal. Data are collected on 12 different properties of the wines one of which is Quality, based on sensory data, and the rest are on chemical properties of the wines including density, acidity, alcohol content etc. All chemical properties of wines are continuous variables. Quality is an ordinal variable with possible ranking from 1 (worst) to 10 (best). Each variety of wine is tasted by three independent tasters and the final rank assigned is the median rank given by the tasters.\n",
    "\n",
    "A predictive model developed on this data is expected to provide guidance to vineyards regarding quality and price expected on their produce without heavy reliance on volatility of wine tasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.029</td>\n",
       "      <td>7.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.99060</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>12.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.045</td>\n",
       "      <td>12.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.99630</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.57</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.49</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.049</td>\n",
       "      <td>50.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.99710</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.57</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.027</td>\n",
       "      <td>5.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.98985</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.32</td>\n",
       "      <td>10.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4489</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.49</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.030</td>\n",
       "      <td>28.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.98926</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.40</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.051</td>\n",
       "      <td>77.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.045</td>\n",
       "      <td>73.5</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0.99340</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.61</td>\n",
       "      <td>9.9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.040</td>\n",
       "      <td>49.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.99540</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.61</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.28</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>31.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99815</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.74</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.045</td>\n",
       "      <td>24.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.99420</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "3566            7.6             0.380         0.28             4.2      0.029   \n",
       "1558            6.2             0.430         0.49             6.4      0.045   \n",
       "1643            8.1             0.300         0.49            12.3      0.049   \n",
       "2754            5.9             0.170         0.28             0.7      0.027   \n",
       "4489            6.7             0.480         0.49             2.9      0.030   \n",
       "580             7.4             0.410         0.66            10.8      0.051   \n",
       "438             7.4             0.155         0.34             2.3      0.045   \n",
       "186             6.7             0.240         0.41             9.4      0.040   \n",
       "786             7.7             0.340         0.28            11.0      0.040   \n",
       "1504            7.0             0.170         0.74            12.8      0.045   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "3566                  7.0                 112.0  0.99060  3.00       0.41   \n",
       "1558                 12.0                 115.0  0.99630  3.27       0.57   \n",
       "1643                 50.0                 144.0  0.99710  3.09       0.57   \n",
       "2754                  5.0                  28.0  0.98985  3.13       0.32   \n",
       "4489                 28.0                 122.0  0.98926  3.13       0.40   \n",
       "580                  77.0                 194.0  0.99760  3.05       0.46   \n",
       "438                  73.5                 214.0  0.99340  3.18       0.61   \n",
       "186                  49.0                 166.0  0.99540  3.12       0.61   \n",
       "786                  31.0                 117.0  0.99815  3.27       0.29   \n",
       "1504                 24.0                 126.0  0.99420  3.26       0.38   \n",
       "\n",
       "      alcohol  quality  \n",
       "3566     12.6        6  \n",
       "1558      9.0        4  \n",
       "1643     10.2        7  \n",
       "2754     10.6        5  \n",
       "4489     13.0        6  \n",
       "580       8.7        5  \n",
       "438       9.9        7  \n",
       "186       9.9        6  \n",
       "786       9.2        6  \n",
       "1504     12.2        8  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = data_w.assign(type = 'white')\n",
    "\n",
    "#data = data.append(data_r.assign(type = 'red'), ignore_index=True)\n",
    "#data.sample(5)\n",
    "\n",
    "data_w.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1\n",
    "\n",
    "Show the frecuency table of the quality by type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='quality',data=data_r,palette= 'hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "3     10\n",
       "4     53\n",
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "8     18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_r.groupby('quality').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='quality',data=data_w,palette= 'hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "3      20\n",
       "4     163\n",
       "5    1457\n",
       "6    2198\n",
       "7     880\n",
       "8     175\n",
       "9       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w.groupby('quality').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.2\n",
    "\n",
    "* Standarized the features (not the quality)\n",
    "* Create a binary target for each type of wine\n",
    "* Create two Linear SVM's for the white and red wines, repectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estandarización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_scaled = pd.DataFrame(index=data_r.index)\n",
    "data_w_scaled = pd.DataFrame(index=data_w.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "for i in data_r.loc[:, data_r.columns != 'quality'].columns:\n",
    "    data_r_scaled[i] = preprocessing.scale(data_r[i])\n",
    "    \n",
    "for j in data_w.loc[:, data_w.columns != 'quality'].columns:\n",
    "    data_w_scaled[j] = preprocessing.scale(data_w[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Creación de variable respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_scaled['response'] = np.where(data_r['quality']>=7,1,0)\n",
    "data_w_scaled['response'] = np.where(data_w['quality']>=7,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "0    1382\n",
       "1     217\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_r_scaled.groupby('response').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "0    3838\n",
       "1    1060\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_scaled.groupby('response').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r_scaled['response']=data_r_scaled['response'].astype(bool)\n",
    "data_w_scaled['response']=data_w_scaled['response'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.528360</td>\n",
       "      <td>0.961877</td>\n",
       "      <td>-1.391472</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.466193</td>\n",
       "      <td>-0.379133</td>\n",
       "      <td>0.558274</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.298547</td>\n",
       "      <td>1.967442</td>\n",
       "      <td>-1.391472</td>\n",
       "      <td>0.043416</td>\n",
       "      <td>0.223875</td>\n",
       "      <td>0.872638</td>\n",
       "      <td>0.624363</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>-0.719933</td>\n",
       "      <td>0.128950</td>\n",
       "      <td>-0.584777</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.298547</td>\n",
       "      <td>1.297065</td>\n",
       "      <td>-1.186070</td>\n",
       "      <td>-0.169427</td>\n",
       "      <td>0.096353</td>\n",
       "      <td>-0.083669</td>\n",
       "      <td>0.229047</td>\n",
       "      <td>0.134264</td>\n",
       "      <td>-0.331177</td>\n",
       "      <td>-0.048089</td>\n",
       "      <td>-0.584777</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.654856</td>\n",
       "      <td>-1.384443</td>\n",
       "      <td>1.484154</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.264960</td>\n",
       "      <td>0.107592</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.664277</td>\n",
       "      <td>-0.979104</td>\n",
       "      <td>-0.461180</td>\n",
       "      <td>-0.584777</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.528360</td>\n",
       "      <td>0.961877</td>\n",
       "      <td>-1.391472</td>\n",
       "      <td>-0.453218</td>\n",
       "      <td>-0.243707</td>\n",
       "      <td>-0.466193</td>\n",
       "      <td>-0.379133</td>\n",
       "      <td>0.558274</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.528360</td>\n",
       "      <td>0.738418</td>\n",
       "      <td>-1.391472</td>\n",
       "      <td>-0.524166</td>\n",
       "      <td>-0.264960</td>\n",
       "      <td>-0.274931</td>\n",
       "      <td>-0.196679</td>\n",
       "      <td>0.558274</td>\n",
       "      <td>1.288643</td>\n",
       "      <td>-0.579207</td>\n",
       "      <td>-0.960246</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.241094</td>\n",
       "      <td>0.403229</td>\n",
       "      <td>-1.083370</td>\n",
       "      <td>-0.666062</td>\n",
       "      <td>-0.392483</td>\n",
       "      <td>-0.083669</td>\n",
       "      <td>0.381091</td>\n",
       "      <td>-0.183745</td>\n",
       "      <td>-0.072005</td>\n",
       "      <td>-1.169337</td>\n",
       "      <td>-0.960246</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.585813</td>\n",
       "      <td>0.682553</td>\n",
       "      <td>-1.391472</td>\n",
       "      <td>-0.949853</td>\n",
       "      <td>-0.477498</td>\n",
       "      <td>-0.083669</td>\n",
       "      <td>-0.774449</td>\n",
       "      <td>-1.137769</td>\n",
       "      <td>0.511130</td>\n",
       "      <td>-1.110324</td>\n",
       "      <td>-0.397043</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.298547</td>\n",
       "      <td>0.291499</td>\n",
       "      <td>-1.288771</td>\n",
       "      <td>-0.382271</td>\n",
       "      <td>-0.307468</td>\n",
       "      <td>-0.657454</td>\n",
       "      <td>-0.865676</td>\n",
       "      <td>0.028261</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>-0.520193</td>\n",
       "      <td>-0.866379</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.470907</td>\n",
       "      <td>-0.155419</td>\n",
       "      <td>0.457144</td>\n",
       "      <td>2.526589</td>\n",
       "      <td>-0.349975</td>\n",
       "      <td>0.107592</td>\n",
       "      <td>1.688677</td>\n",
       "      <td>0.558274</td>\n",
       "      <td>0.251958</td>\n",
       "      <td>0.837107</td>\n",
       "      <td>0.072294</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0      -0.528360          0.961877    -1.391472       -0.453218  -0.243707   \n",
       "1      -0.298547          1.967442    -1.391472        0.043416   0.223875   \n",
       "2      -0.298547          1.297065    -1.186070       -0.169427   0.096353   \n",
       "3       1.654856         -1.384443     1.484154       -0.453218  -0.264960   \n",
       "4      -0.528360          0.961877    -1.391472       -0.453218  -0.243707   \n",
       "5      -0.528360          0.738418    -1.391472       -0.524166  -0.264960   \n",
       "6      -0.241094          0.403229    -1.083370       -0.666062  -0.392483   \n",
       "7      -0.585813          0.682553    -1.391472       -0.949853  -0.477498   \n",
       "8      -0.298547          0.291499    -1.288771       -0.382271  -0.307468   \n",
       "9      -0.470907         -0.155419     0.457144        2.526589  -0.349975   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0            -0.466193             -0.379133  0.558274  1.288643  -0.579207   \n",
       "1             0.872638              0.624363  0.028261 -0.719933   0.128950   \n",
       "2            -0.083669              0.229047  0.134264 -0.331177  -0.048089   \n",
       "3             0.107592              0.411500  0.664277 -0.979104  -0.461180   \n",
       "4            -0.466193             -0.379133  0.558274  1.288643  -0.579207   \n",
       "5            -0.274931             -0.196679  0.558274  1.288643  -0.579207   \n",
       "6            -0.083669              0.381091 -0.183745 -0.072005  -1.169337   \n",
       "7            -0.083669             -0.774449 -1.137769  0.511130  -1.110324   \n",
       "8            -0.657454             -0.865676  0.028261  0.316751  -0.520193   \n",
       "9             0.107592              1.688677  0.558274  0.251958   0.837107   \n",
       "\n",
       "    alcohol  response  \n",
       "0 -0.960246     False  \n",
       "1 -0.584777     False  \n",
       "2 -0.584777     False  \n",
       "3 -0.584777     False  \n",
       "4 -0.960246     False  \n",
       "5 -0.960246     False  \n",
       "6 -0.960246     False  \n",
       "7 -0.397043      True  \n",
       "8 -0.866379      True  \n",
       "9  0.072294     False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_r_scaled.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creación SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = data_r_scaled.loc[:,:'alcohol']\n",
    "y_r = data_r_scaled.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_r = SVC(kernel='linear')\n",
    "clf_r.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino rojo - Kernel LINEAR\n",
      "0.8642901813633521\n"
     ]
    }
   ],
   "source": [
    "r1=clf_r.score(X_r, y_r)\n",
    "print(\"Score vino rojo - Kernel LINEAR\")\n",
    "print(clf_r.score(X_r, y_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w = data_w_scaled.loc[:,:'alcohol']\n",
    "y_w = data_w_scaled.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_w = SVC(kernel='linear')\n",
    "clf_w.fit(X_w, y_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino blanco - Kernel LINEAR\n",
      "0.7835851367905268\n"
     ]
    }
   ],
   "source": [
    "w1=clf_w.score(X_w, y_w)\n",
    "print(\"Score vino blanco - Kernel LINEAR\")\n",
    "print(clf_w.score(X_w, y_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.3\n",
    "\n",
    "Test the two SVM's using the different kernels (‘poly’, ‘rbf’, ‘sigmoid’)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: Poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_r = SVC(kernel='poly',gamma=\"auto\")\n",
    "clf_r.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino rojo - Kernel POLY\n",
      "0.908692933083177\n"
     ]
    }
   ],
   "source": [
    "r2=clf_r.score(X_r, y_r)\n",
    "print(\"Score vino rojo - Kernel POLY\")\n",
    "print(clf_r.score(X_r, y_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_w = SVC(kernel='poly',gamma=\"auto\")\n",
    "clf_w.fit(X_w, y_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino blanco - Kernel POLY\n",
      "0.8156390363413638\n"
     ]
    }
   ],
   "source": [
    "w2=clf_w.score(X_w, y_w)\n",
    "print(\"Score vino blanco - Kernel POLY\")\n",
    "print(clf_w.score(X_w, y_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: rbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_r = SVC(kernel='rbf',gamma=\"auto\")\n",
    "clf_r.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino rojo - Kernel RBF\n",
      "0.8986866791744841\n"
     ]
    }
   ],
   "source": [
    "r3=clf_r.score(X_r, y_r)\n",
    "print(\"Score vino rojo - Kernel RBF\")\n",
    "print(clf_r.score(X_r, y_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_w = SVC(kernel='rbf',gamma=\"auto\")\n",
    "clf_w.fit(X_w, y_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino blanco - Kernel RBF\n",
      "0.8409554920375664\n"
     ]
    }
   ],
   "source": [
    "w3=clf_w.score(X_w, y_w)\n",
    "print(\"Score vino blanco - Kernel RBF\")\n",
    "print(clf_w.score(X_w, y_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel: sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_r = SVC(kernel='sigmoid',gamma=\"auto\")\n",
    "clf_r.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino rojo - Kernel SIGMOID\n",
      "0.8311444652908068\n"
     ]
    }
   ],
   "source": [
    "r4=clf_r.score(X_r, y_r)\n",
    "print(\"Score vino rojo - Kernel SIGMOID\")\n",
    "print(clf_r.score(X_r, y_r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='sigmoid',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "clf_w = SVC(kernel='sigmoid',gamma=\"auto\")\n",
    "clf_w.fit(X_w, y_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score vino blanco - Kernel SIGMOID\n",
      "0.7133523887300939\n"
     ]
    }
   ],
   "source": [
    "w4=clf_w.score(X_w, y_w)\n",
    "print(\"Score vino blanco - Kernel SIGMOID\")\n",
    "print(clf_w.score(X_w, y_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tabla de performance para cada kernel\n",
    "kernels = {'Wine_type': ['Rojo','Rojo','Rojo','Rojo','Blanco','Blanco','Blanco','Blanco'],\n",
    "           'Kernel':['Linear','Poly','RBF','Sigmoid','Linear','Poly','RBF','Sigmoid'],\n",
    "           'Score':[r1,r2,r3,r4,w1,w2,w3,w4]\n",
    "          }\n",
    "\n",
    "df_ = pd.DataFrame(kernels,columns=['Wine_type','Kernel','Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine_type</th>\n",
       "      <th>Kernel</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rojo</td>\n",
       "      <td>Linear</td>\n",
       "      <td>0.864290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rojo</td>\n",
       "      <td>Poly</td>\n",
       "      <td>0.908693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rojo</td>\n",
       "      <td>RBF</td>\n",
       "      <td>0.898687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rojo</td>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>0.831144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blanco</td>\n",
       "      <td>Linear</td>\n",
       "      <td>0.783585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blanco</td>\n",
       "      <td>Poly</td>\n",
       "      <td>0.815639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blanco</td>\n",
       "      <td>RBF</td>\n",
       "      <td>0.840955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Blanco</td>\n",
       "      <td>Sigmoid</td>\n",
       "      <td>0.713352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Wine_type   Kernel     Score\n",
       "0      Rojo   Linear  0.864290\n",
       "1      Rojo     Poly  0.908693\n",
       "2      Rojo      RBF  0.898687\n",
       "3      Rojo  Sigmoid  0.831144\n",
       "4    Blanco   Linear  0.783585\n",
       "5    Blanco     Poly  0.815639\n",
       "6    Blanco      RBF  0.840955\n",
       "7    Blanco  Sigmoid  0.713352"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada tipo de vino se corrió SVM cambiando el tipo de kernel: linear, poly, rbf y sigmoid. En el caso del vino rojo el mejor caso de SVM se presenta con el kernel poly, mientras que para el vino blanco el mejor caso de SVM se presenta con el kernel RBF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "Using the best SVM find the parameters that gives the best performance\n",
    "\n",
    "'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_array = {'gamma':[0.01,0.001,0.0001]}\n",
    "c_array = {'c':[0.1,1,10,100,1000]}\n",
    "\n",
    "gamma_iter = pd.DataFrame(gamma_array,columns=['gamma'])\n",
    "c_iter = pd.DataFrame(c_array,columns=['c'])\n",
    "\n",
    "resultado = pd.DataFrame(index=c_iter.index, columns=gamma_iter.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in gamma_iter['gamma'].iteritems():\n",
    "    for j in c_iter['c'].iteritems():\n",
    "\n",
    "        from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
    "        best_clf_r = SVC(kernel='poly',gamma=i[1],C=j[1])\n",
    "        best_clf_r.fit(X_r, y_r)   \n",
    "        resultado[i[0]][j[0]]=best_clf_r.score(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.001</th>\n",
       "      <th>0.0001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.865541</td>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.879925</td>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.910569</td>\n",
       "      <td>0.86429</td>\n",
       "      <td>0.86429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0.01    0.001   0.0001\n",
       "0.1    0.86429  0.86429  0.86429\n",
       "1      0.86429  0.86429  0.86429\n",
       "10    0.865541  0.86429  0.86429\n",
       "100   0.879925  0.86429  0.86429\n",
       "1000  0.910569  0.86429  0.86429"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.columns = ['0.01', '0.001','0.0001']\n",
    "resultado.index = [\"0.1\",\"1\",\"10\",\"100\",\"1000\"]\n",
    "resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del vino rojo los parámentros que mejor ajustan el SVM son: gamma=0.01 y c=1000, donde el accuracy score es de 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Compare the results with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "\n",
    "* Train a linear regression to predict wine quality (Continous)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creación de la variable respuesta para los datos no estandarizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r['response'] = np.where(data_r['quality']>=7,1,0)\n",
    "data_w['response'] = np.where(data_w['quality']>=7,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable respuesta, variables explicativas y partición de la base para vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = data_r_scaled.loc[:,:'alcohol']\n",
    "y_r = data_r_scaled.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_r, y_r, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión lineal vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04630535 -0.03936439  0.01173109  0.02900463 -0.0388415   0.00066512\n",
      " -0.02984049 -0.06063468 -0.01483385  0.06190569  0.0866446 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_r = LinearRegression()\n",
    "lr_r.fit(Xr_train, yr_train)\n",
    "print(lr_r.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_pred = lr_r.predict(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.28446073702392977\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(yr_test, yr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable respuesta, variables explicativas y partición de la base para vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w = data_w_scaled.loc[:,:'alcohol']\n",
    "y_w = data_w_scaled.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(X_w, y_w, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regresión lineal vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03596195 -0.02987781 -0.00364902  0.14743294 -0.01215049  0.02586374\n",
      " -0.01125274 -0.17864918  0.04895383  0.02625588  0.08046014]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_w = LinearRegression()\n",
    "lr_w.fit(Xw_train, yw_train)\n",
    "print(lr_w.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_pred = lr_w.predict(Xw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.37450627270819364\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(yw_test, yw_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "* Estimate a ridge regression with alpha equals 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02895991 -0.03902609  0.01743504  0.02160401 -0.0355135  -0.00057645\n",
      " -0.02798261 -0.0444929  -0.01747081  0.05403442  0.0868928 ]\n",
      "0.28381295774459386\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.1\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg_r = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg_r.fit(Xr_train, yr_train)\n",
    "yr_pred = ridgereg_r.predict(Xr_test)\n",
    "print(ridgereg_r.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yr_test, yr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0132711  -0.03147716  0.02010845  0.00931349 -0.01897159 -0.00430832\n",
      " -0.01739563 -0.02411709 -0.00861624  0.02959549  0.0561034 ]\n",
      "0.286213078627286\n"
     ]
    }
   ],
   "source": [
    "# alpha=1\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg_r = Ridge(alpha=1, normalize=True)\n",
    "ridgereg_r.fit(Xr_train, yr_train)\n",
    "yr_pred = ridgereg_r.predict(Xr_test)\n",
    "print(ridgereg_r.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yr_test, yr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00624771 -0.02765957 -0.00316241  0.0569254  -0.02142435  0.02654574\n",
      " -0.01580322 -0.05943845  0.02417077  0.01785435  0.11562642]\n",
      "0.37673992370799814\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.1\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg_w = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg_w.fit(Xw_train, yw_train)\n",
    "yw_pred = ridgereg_w.predict(Xw_test)\n",
    "print(ridgereg_w.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yw_test, yw_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00447162 -0.01349291 -0.00094729  0.00746632 -0.02387114  0.01052694\n",
      " -0.0129028  -0.02993252  0.01211427  0.00924476  0.06201718]\n",
      "0.38635433531025165\n"
     ]
    }
   ],
   "source": [
    "# alpha=1\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg_w = Ridge(alpha=1, normalize=True)\n",
    "ridgereg_w.fit(Xw_train, yw_train)\n",
    "yw_pred = ridgereg_w.predict(Xw_test)\n",
    "print(ridgereg_w.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yw_test, yw_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "* Estimate a lasso regression with alpha equals 0.01, 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -0.  0.  0. -0. -0. -0. -0. -0.  0.  0.]\n",
      "0.317493040268925\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.01\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg_r = Lasso(alpha=0.01, normalize=True)\n",
    "lassoreg_r.fit(Xr_train, yr_train)\n",
    "yr_pred = lassoreg_r.predict(Xr_test)\n",
    "print(lassoreg_r.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yr_test, yr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -0.  0.  0. -0. -0. -0. -0. -0.  0.  0.]\n",
      "0.317493040268925\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.1\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg_r = Lasso(alpha=0.1, normalize=True)\n",
    "lassoreg_r.fit(Xr_train, yr_train)\n",
    "yr_pred = lassoreg_r.predict(Xr_test)\n",
    "print(lassoreg_r.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yr_test, yr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -0.  0.  0. -0. -0. -0. -0. -0.  0.  0.]\n",
      "0.317493040268925\n"
     ]
    }
   ],
   "source": [
    "# alpha=1\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg_r = Lasso(alpha=1, normalize=True)\n",
    "lassoreg_r.fit(Xr_train, yr_train)\n",
    "yr_pred = lassoreg_r.predict(Xr_test)\n",
    "print(lassoreg_r.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yr_test, yr_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.]\n",
      "0.42435715129948487\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.01\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg_w = Lasso(alpha=0.01, normalize=True)\n",
    "lassoreg_w.fit(Xw_train, yw_train)\n",
    "yw_pred = lassoreg_r.predict(Xw_test)\n",
    "print(lassoreg_w.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yw_test, yw_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.]\n",
      "0.42435715129948487\n"
     ]
    }
   ],
   "source": [
    "# alpha=0.1\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg_w = Lasso(alpha=0.1, normalize=True)\n",
    "lassoreg_w.fit(Xw_train, yw_train)\n",
    "yw_pred = lassoreg_r.predict(Xw_test)\n",
    "print(lassoreg_w.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yw_test, yw_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0. -0. -0. -0. -0. -0. -0. -0.  0.  0.  0.]\n",
      "0.42435715129948487\n"
     ]
    }
   ],
   "source": [
    "# alpha=1\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg_w = Lasso(alpha=1, normalize=True)\n",
    "lassoreg_w.fit(Xw_train, yw_train)\n",
    "yw_pred = lassoreg_r.predict(Xw_test)\n",
    "print(lassoreg_w.coef_)\n",
    "print(np.sqrt(metrics.mean_squared_error(yw_test, yw_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "* Create a binary target\n",
    "\n",
    "* Train a logistic regression to predict wine quality (binary)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_r = data_r.loc[:,:'alcohol']\n",
    "y_r = data_r.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_r, y_r, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_r = LogisticRegression(C=1e9,solver='liblinear',multi_class='ovr')\n",
    "logreg_r.fit(Xr_train, yr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.01328886  -3.71614267  -0.20959607   0.13489944 -11.90254804\n",
      "    0.02334655  -0.02201683  -2.93158945  -1.91683349   3.43694096\n",
      "    0.95768815]]\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "print(logreg_r.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_pred = logreg_r.predict(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37333333333333335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94       355\n",
      "          1       0.47      0.31      0.37        45\n",
      "\n",
      "avg / total       0.87      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(metrics.f1_score(yr_test, yr_pred))\n",
    "print(metrics.classification_report(yr_test, yr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w = data_w.loc[:,:'alcohol']\n",
    "y_w = data_w.loc[:,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xw_train, Xw_test, yw_train, yw_test = train_test_split(X_w, y_w, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg_w = LogisticRegression(C=1e9,solver='liblinear',multi_class='ovr')\n",
    "logreg_w.fit(Xw_train, yw_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.08578525e-02 -4.20010278e+00 -1.40061312e+00  6.16688647e-02\n",
      "  -8.91419982e+00  1.25352404e-02 -3.14078991e-03 -7.24884511e+00\n",
      "   1.11237125e+00  1.09638839e+00  8.95921821e-01]]\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "print(logreg_w.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "yw_pred = logreg_w.predict(Xw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36082474226804123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88       951\n",
      "          1       0.61      0.26      0.36       274\n",
      "\n",
      "avg / total       0.77      0.80      0.76      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(metrics.f1_score(yw_test, yw_pred))\n",
    "print(metrics.classification_report(yw_test, yw_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "* Estimate a regularized logistic regression using:\n",
    "* C = 0.01, 0.1 & 1.0\n",
    "* penalty = ['l1, 'l2']\n",
    "* Compare the coefficients and the f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino rojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize X_train and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xr_train = Xr_train.astype(float)\n",
    "Xr_test = Xr_test.astype(float)\n",
    "scaler.fit(Xr_train)\n",
    "Xr_train_scaled = scaler.transform(Xr_train)\n",
    "Xr_test_scaled = scaler.transform(Xr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.04023377  0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.30841664]]\n",
      "0.37333333333333335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94       355\n",
      "          1       0.47      0.31      0.37        45\n",
      "\n",
      "avg / total       0.87      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.01 with L1 penalty\n",
    "logreg_r = LogisticRegression(C=0.01, penalty='l1',solver='liblinear',multi_class='ovr')\n",
    "logreg_r.fit(Xr_train_scaled, yr_train)\n",
    "print(logreg_r.coef_)\n",
    "print(metrics.f1_score(yr_test, yr_pred))\n",
    "print(metrics.classification_report(yr_test, yr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0345644  -0.54846632  0.          0.00383691 -0.22150777  0.\n",
      "  -0.26392134  0.         -0.15708513  0.3985779   0.88789595]]\n",
      "0.37333333333333335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94       355\n",
      "          1       0.47      0.31      0.37        45\n",
      "\n",
      "avg / total       0.87      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.1 with L1 penalty\n",
    "logreg_r = LogisticRegression(C=0.1, penalty='l1',solver='liblinear',multi_class='ovr')\n",
    "logreg_r.fit(Xr_train_scaled, yr_train)\n",
    "print(logreg_r.coef_)\n",
    "print(metrics.f1_score(yr_test, yr_pred))\n",
    "print(metrics.classification_report(yr_test, yr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09787554 -0.21664386  0.11441425  0.06779689 -0.14318555 -0.01489745\n",
      "  -0.134284   -0.16803975 -0.0633881   0.21993611  0.38450383]]\n",
      "0.37333333333333335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94       355\n",
      "          1       0.47      0.31      0.37        45\n",
      "\n",
      "avg / total       0.87      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.01 with L2 penalty\n",
    "logreg_r = LogisticRegression(C=0.01, penalty='l2',solver='liblinear',multi_class='ovr')\n",
    "logreg_r.fit(Xr_train_scaled, yr_train)\n",
    "print(logreg_r.coef_)\n",
    "print(metrics.f1_score(yr_test, yr_pred))\n",
    "print(metrics.classification_report(yr_test, yr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.22562399 -0.43526712  0.08090423  0.18064489 -0.33941735  0.07760623\n",
      "  -0.39413325 -0.30054942 -0.12315759  0.46454466  0.6859149 ]]\n",
      "0.37333333333333335\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.94       355\n",
      "          1       0.47      0.31      0.37        45\n",
      "\n",
      "avg / total       0.87      0.88      0.87       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.1 with L2 penalty\n",
    "logreg_r = LogisticRegression(C=0.1, penalty='l2',solver='liblinear',multi_class='ovr')\n",
    "logreg_r.fit(Xr_train_scaled, yr_train)\n",
    "print(logreg_r.coef_)\n",
    "print(metrics.f1_score(yr_test, yr_pred))\n",
    "print(metrics.classification_report(yr_test, yr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vino blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize X_train and X_test\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "Xw_train = Xw_train.astype(float)\n",
    "Xw_test = Xw_test.astype(float)\n",
    "scaler.fit(Xw_train)\n",
    "Xw_train_scaled = scaler.transform(Xw_train)\n",
    "Xw_test_scaled = scaler.transform(Xw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10513668 -0.33410711 -0.052508    0.55107258 -0.34761038  0.14506386\n",
      "  -0.03166446 -0.52548951  0.22444785  0.12482736  0.74930611]]\n",
      "0.36082474226804123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88       951\n",
      "          1       0.61      0.26      0.36       274\n",
      "\n",
      "avg / total       0.77      0.80      0.76      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.01 with L1 penalty\n",
    "logreg_w = LogisticRegression(C=0.01, penalty='l1',solver='liblinear',multi_class='ovr')\n",
    "logreg_w.fit(Xw_train_scaled, yw_train)\n",
    "print(logreg_w.coef_)\n",
    "print(metrics.f1_score(yw_test, yw_pred))\n",
    "print(metrics.classification_report(yw_test, yw_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10438231 -0.33413041 -0.05254101  0.54880666 -0.34781615  0.14517822\n",
      "  -0.03183658 -0.52181327  0.22384747  0.12463341  0.75104377]]\n",
      "0.36082474226804123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88       951\n",
      "          1       0.61      0.26      0.36       274\n",
      "\n",
      "avg / total       0.77      0.80      0.76      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.1 with L1 penalty\n",
    "logreg_w = LogisticRegression(C=0.1, penalty='l1',solver='liblinear',multi_class='ovr')\n",
    "logreg_w.fit(Xw_train_scaled, yw_train)\n",
    "print(logreg_w.coef_)\n",
    "print(metrics.f1_score(yw_test, yw_pred))\n",
    "print(metrics.classification_report(yw_test, yw_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20943978 -0.34716073 -0.08425733  0.75758838 -0.36030914  0.18143134\n",
      "  -0.06972955 -0.8171106   0.30264376  0.1567513   0.62065764]]\n",
      "0.36082474226804123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88       951\n",
      "          1       0.61      0.26      0.36       274\n",
      "\n",
      "avg / total       0.77      0.80      0.76      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.1 with L2 penalty\n",
    "logreg_w = LogisticRegression(C=0.1, penalty='l2',solver='liblinear',multi_class='ovr')\n",
    "logreg_w.fit(Xw_train_scaled, yw_train)\n",
    "print(logreg_w.coef_)\n",
    "print(metrics.f1_score(yw_test, yw_pred))\n",
    "print(metrics.classification_report(yw_test, yw_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03978779 -0.20583929 -0.03605984  0.26421405 -0.24244797  0.14439889\n",
      "  -0.08866439 -0.27645694  0.14604219  0.09536205  0.60562424]]\n",
      "0.36082474226804123\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.95      0.88       951\n",
      "          1       0.61      0.26      0.36       274\n",
      "\n",
      "avg / total       0.77      0.80      0.76      1225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try C=0.01 with L2 penalty\n",
    "logreg_w = LogisticRegression(C=0.01, penalty='l2',solver='liblinear',multi_class='ovr')\n",
    "logreg_w.fit(Xw_train_scaled, yw_train)\n",
    "print(logreg_w.coef_)\n",
    "print(metrics.f1_score(yw_test, yw_pred))\n",
    "print(metrics.classification_report(yw_test, yw_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
