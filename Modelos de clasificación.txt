Problemas de clasificación. Hay una gran cantidad de algoritmos que permiten realizar problemas de clasificación. Normalmente, los investigadores tienen una set de algoritmos que son de su experticia o que conocen de mejor manera. Usualmente es intuitiva la manera en que se toma la decisión de aplicar un algoritmo dependiendo del campo de mayor conocimiento en el que se mueve: si el foco es estadístico, los modelos lineales generalizados; si el foco es inteligencia artificial, pueden inclinarse por árboles de decisión o redes neuronales e incluso ensamblaje de varios modelos.
Los datos con los que se trabajan influyen mucho en la precisión de cada modelo, no todos los algoritmos tienen niveles de precisión altos con diferentes sets de datos. Algunos algoritmos pueden ajustarse muy bien a algunos sets de datos, mientras que para otros sets presenta niveles muy bajos de precisión. En el análisis que se presenta en el paper se evidencia el buen performance que ofrecen los modelos de Random Forest en paralelo, en donde en la mayoría de experimentos presenta los mejores niveles de precisión, seguido por modelos de SVM y Redes Neuronales.
Estos experimentos se realizaron en varios paquetes de modelamiento (R, C, Matlab, etc.), por lo que la única diferencia es el rendimiento computacional, además los sets de datos que fueron seleccionados para los algoritmos tienen diferentes características que ayudan a establecer contextos hetereogéneos para medir los rendimientos. Hay sets de datos reales, datos con un número elevado de observaciones, otros con pocas observaciones y las variables también varían. 
Los resultados muestran rangos de precisión en donde las diferentes familias de clasificación se comportan con un patrón general, esto no quiere decir que para todos los ejercicios Random Forest haya sido el mejor algoritmo, sino que en la mayoría de los casos, surango de precisión se ubicó por encima del resto. SVM y Redes neuronales son algoritmos que también presentan muy buenos niveles de precisión.
